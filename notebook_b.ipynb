{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "from torch.distributions import constraints\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
    "from pyro.infer import Predictive\n",
    "import pyro.optim as optim\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyro vocabulary\n",
    "---\n",
    "\n",
    "## model\n",
    "\n",
    "- `model` : any function is a model.\n",
    "It is a \"composition of primitive stochastic functions and deterministic computations\".\n",
    "$P(X| \\theta)$\n",
    "A stochastic function can be any Python object with a `__call__()` method, like a function, a method, or a PyTorch `nn.Module`.\n",
    "\n",
    "\n",
    "``` python\n",
    "def weather(temp_yesterday):\n",
    "    temp_today = pyro.sample(\"temp_today\", dist.Normal(temp_yesterday, 1.0))\n",
    "    measurement = pyro.sample(\"measurement\", dist.Normal(temp_today, 0.75))\n",
    "    return measurement\n",
    "```\n",
    "\n",
    "NB: `measurement` is output, `temp_yesterday` is input, `temp_today` is latent\n",
    "weather() yields a measurement $M | T_y$\n",
    "\n",
    "<!-- or $P(M | T_t) P(T_t | T_y)$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## sample\n",
    "- `sample` : get a collection of independent rv from the same primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample('now', lambda : [1]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hot(temperature):\n",
    "    if temperature > 10:\n",
    "        return lambda : True\n",
    "    else:\n",
    "        return lambda : False\n",
    "        \n",
    "pyro.sample('now', hot(12)), pyro.sample('now', hot(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with pyro.distributions the shapes are broadcasted :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0470, 1.0677, 0.0269],\n",
       "        [1.3179, 0.0765, 1.0546]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample(\"normal_sample\", dist.Normal(torch.ones(2,3), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Shapes\n",
    "3(!) different shapes at play:\n",
    "\n",
    "- sample_shape\n",
    "- batch_shape \n",
    "- event_shape\n",
    "\n",
    "pytorch tensor has only one shape attribute `.shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(2,3)\n",
    "ones.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyro distribution has two shapes: `batch_shape` and `event_shape`:\n",
    "\n",
    "(by the shapes are broadcasted in pyro distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_norm = dist.Normal(torch.ones(2,3), 1)\n",
    "d_norm.batch_shape, d_norm.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mnorm = dist.MultivariateNormal(torch.ones(3), torch.eye(3))\n",
    "d_mnorm.batch_shape, d_mnorm.event_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices over `.batch_shape` denote conditionally independent random variables, \n",
    "whereas indices over `.event_shape` denote dependent random variables (i.e. one draw from a distribution). Because the dependent random variables define probability together, the `.log_prob()` method only produces a single number for each event of shape `.event_shape`. Thus the total shape of `.log_prob()` is .batch_shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_norm.log_prob(torch.rand(2, 3)).shape, d_norm.log_prob(torch.rand(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_norm.log_prob(torch.rand(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mnorm.log_prob(torch.rand(1)).shape, d_mnorm.log_prob(torch.rand(3)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample_shape\n",
    "- batch_shape \n",
    "- event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 7), torch.Size([]), torch.Size([3]), torch.Size([8, 7, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_shape = (8, 7)\n",
    "current_dist = d_mnorm\n",
    "data = current_dist.sample(sample_shape)\n",
    "assert data.shape == sample_shape + current_dist.batch_shape + current_dist.event_shape\n",
    "sample_shape, current_dist.batch_shape, current_dist.event_shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 7), torch.Size([2, 3]), torch.Size([]), torch.Size([8, 7, 2, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_shape = (8, 7)\n",
    "current_dist = d_norm\n",
    "data = current_dist.sample(sample_shape)\n",
    "assert data.shape == sample_shape + current_dist.batch_shape + current_dist.event_shape\n",
    "sample_shape,  current_dist.batch_shape, current_dist.event_shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Condition\n",
    "\n",
    "- `condition`: we can condition on \n",
    "\n",
    "\n",
    "``` python\n",
    "def weather(temp_yesterday):\n",
    "    temp_today = pyro.sample(\"temp_today\", dist.Normal(temp_yesterday, 1.0))\n",
    "    measurement = pyro.sample(\"measurement\", dist.Normal(temp_today, 0.75))\n",
    "    return measurement\n",
    "```\n",
    "\n",
    "$P(M | T_y)$ but in fact $P(M | T_t) P(T_t| T_y)$,\n",
    "\n",
    "so we can $P(M | T_y, T_x = t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.9269), tensor(9.8178))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weather(temp_yesterday):\n",
    "    temp_today = pyro.sample(\"temp_today\", dist.Normal(temp_yesterday, 1.0))\n",
    "    measurement = pyro.sample(\"measurement\", dist.Normal(temp_today, 1.0))\n",
    "    return measurement\n",
    "\n",
    "conditioned_weather = pyro.condition(weather, data={\"temp_today\": 10.})\n",
    "\n",
    "weather(10), conditioned_weather(10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `condition` statement can cast as `obs` argument to `sample`\n",
    "\n",
    "``` python\n",
    "def weather(temp_yesterday):\n",
    "    temp_today = pyro.sample(\"temp_today\", dist.Normal(temp_yesterday, 1.0))\n",
    "    measurement = pyro.sample(\"measurement\", dist.Normal(temp_today, 1.0), obs=5)\n",
    "    return measurement\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_  | iid | independent | dependent\n",
    "--- | --- | --- | ---\n",
    "*shape* | `sample_shape` | `batch_shape` | `event_shape`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "\n",
    "Given $P(X| \\theta_{obs}, \\theta_{unobs})$ infer the posterior $P(\\theta_{obs}, \\theta_{unobs} | X)$.\n",
    "\n",
    "Posterior in fact can be understood as an optimal $\\varphi (\\theta_{obs}, \\theta_{unobs})$ from a certain class of functions, such that \n",
    "\n",
    "a certain loss function is minimized. Could be $\\mathbb{E}_\\varphi [\\log P(X,  \\theta_{obs} \\theta_{unobs}) - \\log\\varphi (\\theta_{obs}, \\theta_{unobs})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guide\n",
    "\n",
    "- `guide` : is such an optimal approximation of the posterior $\\varphi (\\theta_{obs}, \\theta_{unobs})$\n",
    "\n",
    "quote :\n",
    "\n",
    "Inference algorithms in Pyro, such as pyro.infer.SVI, allow us to use arbitrary stochastic functions, which we will call guide functions or guides, as approximate posterior distributions. Guide functions must satisfy these two criteria to be valid approximations for a particular model: \n",
    "\n",
    "- all unobserved (i.e., not conditioned) sample statements that appear in the model appear in the guide. \n",
    "- the guide has the same input signature as the model (i.e., takes the same arguments).\n",
    "\n",
    "Guide functions can serve as programmable, data-dependent proposal distributions for importance sampling, rejection sampling, sequential Monte Carlo, MCMC, and independent Metropolis-Hastings, and as variational distributions or inference networks for stochastic variational inference. Currently, importance sampling, MCMC, and stochastic variational inference are implemented in Pyro, and we plan to add other algorithms in the future.\n",
    "\n",
    "Although the precise meaning of the guide is different across different inference algorithms, the guide function should generally be chosen so that, in principle, it is flexible enough to closely approximate the distribution over all unobserved sample statements in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
